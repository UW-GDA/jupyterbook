{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: ERA5 Climate download\n",
    "\n",
    "## Notebook #0: Data Download\n",
    "\n",
    "UW Geospatial Data Analysis  \n",
    "CEE498/CEWA599  \n",
    "David Shean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary packages to open GRIB files (default ERA5 format) with xarray\n",
    "\n",
    "https://github.com/ecmwf/cfgrib\n",
    "\n",
    "While you wait, open a terminal and inspect the contents of the era5 directory, and review this information\n",
    "* http://xarray.pydata.org/en/stable/io.html#grib-format-via-cfgrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install -y -c conda-forge cfgrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the prepared dataset sample\n",
    "* We could request directly fro CDS API, but this will require at least 5-10 minutes to fulfill, maybe hours\n",
    "* I downloaded some sample ERA5 datasets, created a zip file, staged and shared on Google Drive (accessible to anyone with link)\n",
    "    * https://drive.google.com/open?id=1gomQR_lvhuww_xyR6wcUiziS12x1yCSx\n",
    "* We can use the `drivanon` convenience package to easily download anonymously without authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install directly from github repo main branch\n",
    "%pip install git+https://github.com/friedrichknuth/driveanon.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import driveanon as da\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'era5_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_unzip(out_fn):\n",
    "    #Download\n",
    "    if not os.path.exists(out_fn):\n",
    "        da.save(blob_id, filename=out_fn)\n",
    "    #Extract to subdirectory\n",
    "    if not os.path.exists(os.path.splitext(out_fn)[0]):\n",
    "        with zipfile.ZipFile(out_fn, 'r') as zip_ref:\n",
    "            zip_ref.extractall(os.path.splitext(out_fn)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to load and combine grib files into a single xarray DataSet\n",
    "* Also creates a new, compressed netcdf (nc) file to store the data for future use\n",
    "* See relevant doc on opening and writing files: http://xarray.pydata.org/en/stable/io.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grib2nc(out_fn, writeout=True, compress=False):\n",
    "    if not os.path.exists(out_fn):\n",
    "        #Get all grib filenames in the directory\n",
    "        paths = sorted(glob(os.path.splitext(out_fn)[0]+'*.grib'))\n",
    "        #Generate xarray dataset list, opening with cfgrib engine\n",
    "        datasets = [xr.open_dataset(p, engine='cfgrib') for p in paths]\n",
    "        #Concatenate all datasets along the time axis\n",
    "        combined = xr.concat(datasets, dim='time')\n",
    "        #Drop unnecessary coordinates\n",
    "        combined = combined.drop(['number', 'surface', 'step', 'valid_time'])\n",
    "        if writeout:\n",
    "            encoding = {}\n",
    "            if compress:\n",
    "                #Set up encoding parameters to use compression when writing netcdf file\n",
    "                comp = dict(zlib=True, complevel=9)\n",
    "                encoding = {var: comp for var in combined.data_vars}\n",
    "            #Write out\n",
    "            combined.to_netcdf(out_fn, encoding=encoding)\n",
    "    #else:\n",
    "    #    combined = xr.open_dataset(out_fn)\n",
    "    #return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_id = '1Gwkg21LPKxvZsjwMrwVESGi2ZaVLQP58'\n",
    "out_fn = f'{outdir}/ecv-for-climate-change.zip'\n",
    "download_unzip(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.path.splitext(out_fn)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $datadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_list = ['climatology_0.25g_ea_2t.nc', \\\n",
    "           '1month_anomaly_Global_ea_2t.nc', \\\n",
    "           '1month_mean_Global_ea_2t.nc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for out_fn in fn_list:\n",
    "    grib2nc(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_id = '1nWjcjlqzkSqi-3u2vXt-5ya4VRSKS7v5'\n",
    "out_fn = f'{outdir}/era5_WA_1979-2021_6hr.zip'\n",
    "download_unzip(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.path.splitext(out_fn)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $datadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_list = ['era5_WA_1979-2021_6hr_2m_temperature.nc', \\\n",
    "           'era5_WA_1979-2021_6hr_total_precipitation.nc', \n",
    "           'era5_WA_1979-2021_6hr_snow_depth.nc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for out_fn in fn_list:\n",
    "    grib2nc(out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old files from 2018"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "blob_id = '1bW9FRpnLGCDPsy0khcEfcL7A07ZmgJw6'\n",
    "out_fn = 'era5/era5_week10.tar'\n",
    "if not os.path.exists(out_fn):\n",
    "    da.save(blob_id, filename=out_fn)\n",
    "    !tar -xvf era5/era5_week10.tar -C era5\n",
    "    !unzip -d era5 era5/era5_climatology_1979-2018_1month.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The following will take a few minutes, take the time to review the remainder of the lab"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "blob_id = '1gomQR_lvhuww_xyR6wcUiziS12x1yCSx'\n",
    "out_fn = 'era5/era5_climatology_t_anomaly_1979-2018_1month.zip'\n",
    "if not os.path.exists(out_fn):\n",
    "    da.save(blob_id, filename=out_fn)\n",
    "    !unzip -d era5 era5/era5_climatology_t_anomaly_1979-2018_1month.zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
